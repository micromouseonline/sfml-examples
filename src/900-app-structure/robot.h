//
// Created by peter on 02/11/2024.
//

#ifndef ROBOT_H
#define ROBOT_H

#include <SFML/Graphics.hpp>
#include <cmath>

/***
 * The Robot class is the model. It handles the physical properties behavior of the robot hardware.
 * It looks after the pose, and dynamics as well as odometry and sensing.
 *
 *Key Responsibilities for RobotModel
 * Physical Properties:
 *    - Pose: Position (x, y) and orientation (Î¸) of the robot in the simulation world.
 *    - Dynamics: State of the robot, including velocity (linear and angular) and possibly acceleration.
 *    - Physical Dimensions: Size and shape of the robot (useful for collision detection).
 * Behavior:
 *    - Updates to the pose based on velocity inputs.
 *    - Handling dynamics (e.g., ensuring realistic acceleration/deceleration, if modeled).
 *    - Applying kinematic or dynamic constraints (e.g., for differential drive or holonomic robots).
 * Odometry:
 *    - Estimation of position and orientation based on wheel encoder data or similar sensors.
 * Sensing:
 *    - Simulating robot sensors, such as:
 *    - Distance sensors (e.g., lidar, ultrasonic).
 *    - Encoders for odometry.
 *    - IMUs for angular velocity and acceleration.
 *    - Camera or line sensors.
 */

/// FIXME: This is generated by CoPilot:
#include <SFML/Graphics.hpp>

class Robot {
 public:
  Robot(float x, float y, float orientation) : mPosition(x, y), mOrientation(orientation) {}

  void setPosition(float x, float y) { mPosition = {x, y}; }

  sf::Vector2f getPosition() const { return mPosition; }

  void setOrientation(float orientation) { mOrientation = orientation; }

  float getOrientation() const { return mOrientation; }

  void move(float distance) {
    float radians = mOrientation * 3.14159f / 180.0f;  // Convert degrees to radians
    mPosition.x += distance * cos(radians);
    mPosition.y += distance * sin(radians);
  }

  void turn(float angle) {
    mOrientation += angle;
    if (mOrientation >= 360.0f)
      mOrientation -= 360.0f;
    if (mOrientation < 0.0f)
      mOrientation += 360.0f;
  }

 private:
  sf::Vector2f mPosition;  // Position of the robot in the maze
  float mOrientation;      // Orientation of the robot in degrees
};

////////////////////////////////////////////////////////////////////////////////////
/// some ChatGPT here
class RobotModel {
 public:
  struct Pose {
    double x, y, theta;  // Position and orientation
  };

  struct Velocity {
    double linear, angular;  // Linear and angular velocity
  };

  RobotModel(float width, float height, float origin_x, float origin_y) : m_width(width), m_height(height), m_origin_x(origin_x), m_origin_y(origin_y) {
    setPosition(100, 100);
  };
  // Getters
  RobotModel::Pose getPose() const { return pose_; }
  RobotModel::Velocity getVelocity() const { return velocity_; }

  // Set input velocities
  void setInputVelocities(double linear, double angular) {
    velocity_.linear = linear;
    velocity_.angular = angular;
  }
  // Helper: Compute next pose based on current velocity
  void computeNextPose(double dt) {
    pose_.x += velocity_.linear * std::cos(pose_.theta) * dt;
    pose_.y += velocity_.linear * std::sin(pose_.theta) * dt;
    pose_.theta += velocity_.angular * dt;

    // Normalize theta to [0, 2*pi)
    if (pose_.theta > M_PI)
      pose_.theta -= 2 * M_PI;
    if (pose_.theta < -M_PI)
      pose_.theta += 2 * M_PI;
  }

  void update(float deltaTime) {
    computeNextPose(deltaTime);
    float ds = m_speed * deltaTime;
    float dx = std::cos((m_angle - 90) * 3.14 / 180) * ds;
    float dy = std::sin((m_angle - 90) * 3.14 / 180) * ds;
    m_x += dx;
    m_y += dy;
  }

  void setSpeed(float speed) { m_speed = speed; }
  void setOmega(float omega) { m_omega = omega; }
  void setDirection(float angle) { m_angle = angle; }
  void move(sf::Vector2f direction) {
    m_x += direction.x;
    m_y += direction.y;
  }
  void setPosition(float x, float y) {
    m_x = x;
    m_y = y;
  }
  void rotate(float angle) { m_angle += angle; }
  void set_state(int state) { m_state = state; }

  // Add more methods as needed for behaviour and dynamics

  // Simulate sensor readings based on the environment
  std::vector<double> getSensorData() const {
    std::vector<double> readings;

    // Example: Simple distance sensor simulation
    // Use pose and environment data to calculate distances to nearest objects

    // Here you could:
    // - Perform raycasting
    // - Compute distances to walls/obstacles
    // - Add noise for realism

    return readings;  // Return sensor readings
  }

  // private:
  int m_state = 0;  // used to select the section from the texture. Not very efficient
  float m_width = 0;
  float m_height = 0;
  float m_origin_x = 0;
  float m_origin_y = 0;
  float m_x = 0.0f;
  float m_y = 0.0f;      // Position
  float m_angle = 0.0f;  // Angle in radians
  float m_speed = 0.0f;
  float m_omega = 0.f;

  Pose pose_;
  Velocity velocity_;
  double width_, length_;  // Robot dimensions
};

#endif  // ROBOT_H
